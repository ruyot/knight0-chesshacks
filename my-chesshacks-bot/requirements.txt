# ============================================================================
# ChessHacks Core Dependencies
# ============================================================================
annotated-doc==0.0.4
annotated-types==0.7.0
anyio==4.11.0
chess==1.11.2
click==8.1.8
exceptiongroup==1.3.0
fastapi==0.121.2
h11==0.16.0
idna==3.11
pydantic==2.12.4
pydantic_core==2.41.5
python-chess==1.999
sniffio==1.3.1
starlette==0.49.3
typing-inspection==0.4.2
typing_extensions==4.15.0
uvicorn==0.38.0

# ============================================================================
# Neural Network Dependencies (knight0 Engine)
# ============================================================================

# Core ML framework - NumPy for tensor operations
numpy>=1.24.0,<2.0.0

# ONNX Runtime for optimized CPU inference (recommended for production)
# Lightweight and fast - no CUDA required
onnxruntime>=1.16.0

# PyTorch (optional - only needed if using .pt/.pth models)
# Uncomment the line below if you want to use PyTorch models
# torch>=2.0.0,<2.5.0  # CPU-only version

# HuggingFace Hub (optional - for downloading models from HuggingFace)
# Uncomment if you plan to load models from HuggingFace
# huggingface-hub>=0.19.0

# ============================================================================
# Optional: GPU Support
# ============================================================================
# For NVIDIA GPU acceleration, replace onnxruntime with:
# onnxruntime-gpu>=1.16.0
#
# For PyTorch GPU support, replace torch line with:
# torch>=2.0.0,<2.5.0 --index-url https://download.pytorch.org/whl/cu118

# ============================================================================
# Development Tools (optional)
# ============================================================================
# Uncomment these for training/development in separate repo:
# onnx>=1.15.0  # For exporting models to ONNX
# scikit-learn>=1.3.0  # For metrics and evaluation
